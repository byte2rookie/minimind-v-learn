{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "40ddceb8",
   "metadata": {},
   "source": [
    "# SFT\n",
    "[SFT与pretrain阶段在dataset上的不同](http://www.chinasem.cn/article/361510)<br>\n",
    "简而言之，最大的不同就是assistant回答的部分计算loss,而user的部分不计算loss了"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88973992",
   "metadata": {},
   "source": [
    "## SFT单卡代码\n",
    "这里我们参考pretrain阶段的代码来看即可"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b6df9fa",
   "metadata": {},
   "source": [
    "#### 训练参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2be9b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "class sft_args:\n",
    "    out_dir = \"../out\"\n",
    "    epochs = 1\n",
    "    batch_size = 32\n",
    "    learning_rate = 5e-4\n",
    "    device = \"cuda:3\" if torch.cuda.is_available() else \"cpu\"\n",
    "    dtype = \"bfloat16\"\n",
    "    use_wandb = False\n",
    "    wandb_project = \"MiniMind-SFT-512\"\n",
    "    num_workers = 1\n",
    "    ddp = False\n",
    "    accumulation_steps = 8\n",
    "    grad_clip = 1.0\n",
    "    warmup_iters = 0\n",
    "    log_interval = 100\n",
    "    save_interval = 100\n",
    "    local_rank = -1\n",
    "    embed_dim = 512\n",
    "    block_num = 8\n",
    "    max_seqlen = 1024\n",
    "    use_moe = False\n",
    "    data_path = \"../data/sft_data.jsonl\"  # toy_dataset  \n",
    "    # data_path = \"../data/sft_512.jsonl\" #full_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8066a54",
   "metadata": {},
   "source": [
    "#### 加载model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c76c0cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/zyp/miniconda3/envs/minimind/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "查看工作设备 cuda:3\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# 获取当前 notebook 所在目录（trainer/）\n",
    "current_dir = os.path.dirname(os.path.abspath(\"__file__\"))  # 注意 Jupyter 中可能需要调整\n",
    "# 或者直接写死路径\n",
    "current_dir = \"/data/zyp/jinbu/ZZY/minimind-v-learn/trainer\"\n",
    "\n",
    "# 上一级目录就是项目根目录，拼接 model 路径\n",
    "model_dir = os.path.join(os.path.dirname(current_dir), \"model\")\n",
    "sys.path.append(model_dir)\n",
    "\n",
    "# 现在可以用绝对导入\n",
    "from model import MinimindForCausalLM, MinimindConfig\n",
    "train_args = sft_args()\n",
    "train_args.save_dir = os.path.join(train_args.out_dir)\n",
    "# 确保输出目录存在\n",
    "os.makedirs(train_args.save_dir, exist_ok=True)\n",
    "# 初始化模型配置\n",
    "config = MinimindConfig(\n",
    "    embed_dim=train_args.embed_dim,\n",
    "    block_num=train_args.block_num,\n",
    "    max_seqlen=train_args.max_seqlen,\n",
    ")\n",
    "print(f'查看工作设备 {train_args.device}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b32b51c",
   "metadata": {},
   "source": [
    "#### 单卡训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "57051e2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "加载模型参数 ../out/pretrain_512.pth\n",
      "LLM可训练总参数量：38.075 百万\n",
      "bos_id=[2, 77, 95, 95, 85, 315, 3932, 96], eos_id=[1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "res=<|im_start|>system\n",
      "You are a helpful assistant<|im_end|>\n",
      "<|im_start|>user\n",
      "你好吗？<|im_end|>\n",
      "<|im_start|>assistant\n",
      "我很好，谢谢！你呢？<|im_end|>\n",
      "<|im_start|>user\n",
      "我也很好，谢谢！<|im_end|>\n",
      "<|im_start|>assistant\n",
      "太好了！祝你今天愉快！<|im_end|>\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/zyp/jinbu/ZZY/minimind-v-learn/dataset/lm_dataset.py:104: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X = torch.tensor(input_ids[:-1], dtype=torch.long)\n",
      "/data/zyp/jinbu/ZZY/minimind-v-learn/dataset/lm_dataset.py:105: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  Y = torch.tensor(input_ids[1:], dtype=torch.long)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "res=<|im_start|>system\n",
      "You are a helpful assistant<|im_end|>\n",
      "<|im_start|>user\n",
      "你喜欢什么运动？<|im_end|>\n",
      "<|im_start|>assistant\n",
      "我喜欢跑步和游泳。你呢？<|im_end|>\n",
      "<|im_start|>user\n",
      "我喜欢打篮球！<|im_end|>\n",
      "<|im_start|>assistant\n",
      "篮球很棒！是一个很好的团队运动。<|im_end|>\n",
      "\n",
      "X.tolist()= [[2, 95, 101, 315, 81, 89, 211, 69, 91, 97, 233, 313, 81, 233, 77, 233, 84, 81, 88, 92, 82, 97, 88, 233, 77, 95, 95, 85, 315, 3932, 96, 1, 211, 2, 97, 95, 3717, 211, 2899, 926, 433, 1, 211, 2, 77, 95, 95, 85, 315, 3932, 96, 211, 309, 2048, 273, 2088, 1005, 405, 1357, 433, 1, 211, 2, 97, 95, 3717, 211, 4425, 2048, 273, 2088, 1005, 1, 211, 2, 77, 95, 95, 85, 315, 3932, 96, 211, 840, 4780, 1005, 2670, 405, 1279, 3462, 1005, 1, 211, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3], [2, 95, 101, 315, 81, 89, 211, 69, 91, 97, 233, 313, 81, 233, 77, 233, 84, 81, 88, 92, 82, 97, 88, 233, 77, 95, 95, 85, 315, 3932, 96, 1, 211, 2, 97, 95, 3717, 211, 405, 798, 673, 1135, 433, 1, 211, 2, 77, 95, 95, 85, 315, 3932, 96, 211, 2369, 2957, 297, 2510, 275, 405, 1357, 433, 1, 211, 2, 97, 95, 3717, 211, 2369, 1152, 3475, 1005, 1, 211, 2, 77, 95, 95, 85, 315, 3932, 96, 211, 3475, 5216, 1005, 932, 4536, 1983, 1135, 275, 1, 211, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]]\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "import math\n",
    "from torch.utils.data import DataLoader\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# 项目根目录：/data/zyp/jinbu/ZZY/minimind-v-learn\n",
    "root_dir = Path(\"/data/zyp/jinbu/ZZY/minimind-v-learn\")\n",
    "\n",
    "# 将根目录添加到 Python 可搜索路径\n",
    "sys.path.append(str(root_dir))\n",
    "from dataset.lm_dataset import PretrainDataset,SFTDataset\n",
    "\n",
    "def Logger(content):\n",
    "    print(content)\n",
    "\n",
    "def init_model(lm_config):\n",
    "    tokenizer = AutoTokenizer.from_pretrained('../model/')\n",
    "    model = MinimindForCausalLM(lm_config).to(train_args.device)\n",
    "    moe_path = '_moe' if train_args.use_moe else ''\n",
    "    ckp = f'{train_args.save_dir}/pretrain_{lm_config.embed_dim}{moe_path}.pth'\n",
    "    state_dict = torch.load(ckp, map_location=train_args.device)\n",
    "    model.load_state_dict(state_dict, strict=False)\n",
    "    Logger(f'加载模型参数 {ckp}')\n",
    "    Logger(f'LLM可训练总参数量：{sum(p.numel() for p in model.parameters() if p.requires_grad) / 1e6:.3f} 百万')\n",
    "    return model, tokenizer\n",
    "\n",
    "\n",
    "model, tokenizer = init_model(config)\n",
    "train_ds = SFTDataset(\n",
    "    data_path=train_args.data_path,\n",
    "    tokenizer=tokenizer,\n",
    "    max_seqlen=train_args.max_seqlen,\n",
    ")   \n",
    "train_loader = DataLoader(\n",
    "    train_ds,\n",
    "    batch_size=train_args.batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=train_args.num_workers,\n",
    "    pin_memory=True,\n",
    "    drop_last=False\n",
    ")\n",
    "\n",
    "loader = iter(train_loader)\n",
    "(X,Y, loss_mask) = next(loader)\n",
    "# print(f'打印一个 batch 的数据:\\nX: {X}\\nY: {Y}\\nloss_mask: {loss_mask}\\n')\n",
    "# print(f'打印一个 iter 的数据:\\n{next(loader)}\\n')\n",
    "# print(f'数据集大小：{len(train_ds)}, DataLoader 大小：{len(loader)}')\n",
    "print(f\"X.tolist()= {X.tolist()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a2235b8",
   "metadata": {},
   "source": [
    "### 优化器和混合精度设置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "031123ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 优化器方面 选择 AdamW 优化器 并在混精度场景下创建 scaler 进行梯度缩放避免数值下溢\n",
    "from torch import optim\n",
    "from contextlib import nullcontext\n",
    "scaler = torch.cuda.amp.GradScaler(enabled=(train_args.dtype in ['float16', 'bfloat16']))\n",
    "optimizer = optim.AdamW(model.parameters(), lr=train_args.learning_rate)\n",
    "\n",
    "device_type = \"cuda\" if \"cuda\" in train_args.device else \"cpu\"\n",
    "ctx = nullcontext() if device_type == \"cpu\" else torch.cuda.amp.autocast() # 在 cuda 上启动混精度训练，否则空白上下文"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6692d4e1",
   "metadata": {},
   "source": [
    "### 设置训练函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cacab764",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import time\n",
    "iter_per_epoch = len(train_loader) # 计算每个 epoch 的迭代次数\n",
    "def get_lr(current_step, total_steps, lr):\n",
    "    # 余弦退火学习率调度\n",
    "    return lr / 10 + 0.5 * lr * (1 + math.cos(math.pi * current_step / total_steps))\n",
    "\n",
    "def train_epoch(epoch):\n",
    "    loss_fct = nn.CrossEntropyLoss(reduction='none')\n",
    "    start_time = time.time()\n",
    "    for step, (X, Y, loss_mask) in enumerate(train_loader):\n",
    "        X = X.to(train_args.device)\n",
    "        Y = Y.to(train_args.device)\n",
    "        loss_mask = loss_mask.to(train_args.device)\n",
    "        print(f\"loss_mask = {loss_mask}\")\n",
    "        lr = get_lr(epoch * iter_per_epoch + step, train_args.epochs * iter_per_epoch, train_args.learning_rate)\n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group['lr'] = lr\n",
    "\n",
    "        with ctx:\n",
    "            res = model(X)\n",
    "            # print(f\"res={res}\")\n",
    "            # print(f\"X = {X}\")\n",
    "            if torch.isnan(res.logits).any() or torch.isinf(res.logits).any():\n",
    "                Logger(f\"Warning: logits contains NaN/Inf at step {step}\")\n",
    "                # 打印logits的范围，辅助排查\n",
    "                Logger(f\"logits range: {res.logits.min().item()} ~ {res.logits.max().item()}\")\n",
    "            loss = loss_fct(\n",
    "                res.logits.view(-1, res.logits.size(-1)),\n",
    "                Y.view(-1)\n",
    "            ).view(Y.size())\n",
    "            print(f\"loss_mask.sum(): {loss_mask.sum()}\")\n",
    "            loss = (loss * loss_mask).sum() / loss_mask.sum() # 这里的loss 是有效非pad的token的平均loss\n",
    "            # loss += res.aux_loss\n",
    "            loss = loss / train_args.accumulation_steps\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "\n",
    "        if (step + 1) % train_args.accumulation_steps == 0:\n",
    "            scaler.unscale_(optimizer)\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), train_args.grad_clip)\n",
    "\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "\n",
    "            optimizer.zero_grad(set_to_none=True)  # 清空梯度，为下一个iter做准备\n",
    "\n",
    "        if step % train_args.log_interval == 0:\n",
    "            spend_time = time.time() - start_time\n",
    "            Logger(\n",
    "                'Epoch:[{}/{}]({}/{}) loss:{:.3f} lr:{:.12f} epoch_Time:{}min:'.format(\n",
    "                    epoch + 1,\n",
    "                    train_args.epochs,\n",
    "                    step,\n",
    "                    iter_per_epoch,\n",
    "                    loss.item() * train_args.accumulation_steps,\n",
    "                    optimizer.param_groups[-1]['lr'],\n",
    "                    spend_time / (step + 1) * iter_per_epoch // 60 - spend_time // 60))\n",
    "\n",
    "\n",
    "        if (step + 1) % train_args.save_interval == 0:\n",
    "            model.eval()\n",
    "            moe_path = '_moe' if train_args.use_moe else ''\n",
    "            ckp = f'{train_args.save_dir}/sft_full_{config.embed_dim}{moe_path}.pth'\n",
    "            Logger(f'保存模型到 {ckp}')\n",
    "            state_dict = model.state_dict()\n",
    "\n",
    "            state_dict = {k: v.half() for k, v in state_dict.items()}  # 半精度保存\n",
    "            torch.save(state_dict, ckp)\n",
    "            model.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d96b20d6",
   "metadata": {},
   "source": [
    "### 开始训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d119cc40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "res=<|im_start|>system\n",
      "You are a helpful assistant<|im_end|>\n",
      "<|im_start|>user\n",
      "你好吗？<|im_end|>\n",
      "<|im_start|>assistant\n",
      "我很好，谢谢！你呢？<|im_end|>\n",
      "<|im_start|>user\n",
      "我也很好，谢谢！<|im_end|>\n",
      "<|im_start|>assistant\n",
      "太好了！祝你今天愉快！<|im_end|>\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/zyp/jinbu/ZZY/minimind-v-learn/dataset/lm_dataset.py:104: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X = torch.tensor(input_ids[:-1], dtype=torch.long)\n",
      "/data/zyp/jinbu/ZZY/minimind-v-learn/dataset/lm_dataset.py:105: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  Y = torch.tensor(input_ids[1:], dtype=torch.long)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "res=<|im_start|>system\n",
      "You are a helpful assistant<|im_end|>\n",
      "<|im_start|>user\n",
      "你喜欢什么运动？<|im_end|>\n",
      "<|im_start|>assistant\n",
      "我喜欢跑步和游泳。你呢？<|im_end|>\n",
      "<|im_start|>user\n",
      "我喜欢打篮球！<|im_end|>\n",
      "<|im_start|>assistant\n",
      "篮球很棒！是一个很好的团队运动。<|im_end|>\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_mask = tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0]], device='cuda:3')\n",
      "loss_mask.sum(): 40\n",
      "Epoch:[1/1](0/1) loss:4.546 lr:0.000550000000 epoch_Time:0.0min:\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(train_args.epochs):\n",
    "    train_epoch(epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2431606",
   "metadata": {},
   "source": [
    "### BUGs\n",
    "loss_mask出现了.sum为0的问题,经过排查发现是因为\n",
    "```\n",
    "    def _generate_loss_mask(self, input_ids):\n",
    "        loss_mask = [0] * len(input_ids)\n",
    "        i = 0\n",
    "        while i < len(input_ids):\n",
    "            if input_ids[i:i + len(self.bos_id)] == self.bos_id:\n",
    "                start = i + len(self.bos_id)\n",
    "                end = start\n",
    "                while end < len(input_ids):\n",
    "                    if input_ids[end:end + len(self.eos_id)] == self.eos_id:\n",
    "                        break\n",
    "                    end += 1\n",
    "                for j in range(start + 1, min(end + len(self.eos_id) + 1, self.max_length)):\n",
    "                    loss_mask[j] = 1\n",
    "                i = end + len(self.eos_id) if end < len(input_ids) else len(input_ids)\n",
    "            else:\n",
    "                i += 1\n",
    "        return loss_mask\n",
    "```\n",
    "函数中间的`if input_ids[i:i + len(self.bos_id)] == self.bos_id:`  有问题，input_ids作为Tensor无法作为list进行一一比对，所以不能这么操作<br>\n",
    "只好修改了input_ids比对过程，转为List来进行一一比对，随后便正常了"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d764ebc",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "minimind",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
